
ffpipenode_create_video_decoder_from_ffplay()

    pipeline->func_open_video_decoder = func_open_video_decoder;
    pipeline->func_open_audio_output  = func_open_audio_output;
	
	
seek相关的
avformat_seek_file()

    if (ffp->seek_at_start > 0) {
        ffp_seek_to_l(ffp, ffp->seek_at_start);
    }
	
is->seek_req

ffplay中没有的代码：
            ffp_toggle_buffering(ffp, 1);
            ffp_notify_msg3(ffp, FFP_MSG_BUFFERING_UPDATE, 0, 0);

			if (ffp->enable_accurate_seek) {
                is->drop_aframe_count = 0;
                is->drop_vframe_count = 0;
                SDL_LockMutex(is->accurate_seek_mutex);
                if (is->video_stream >= 0) {
                    is->video_accurate_seek_req = 1;
                }
                if (is->audio_stream >= 0) {
                    is->audio_accurate_seek_req = 1;
                }
                SDL_CondSignal(is->audio_accurate_seek_cond);
                SDL_CondSignal(is->video_accurate_seek_cond);
                SDL_UnlockMutex(is->accurate_seek_mutex);
            }
--------------android 平台下jni层开发的doc--------------------------
http://staratsky.iteye.com/blog/1908964
http://blog.csdn.net/xinchen200/article/details/25333047

-----------------android平台sample的文件----------------------
SampleMediaListFragment.java
VideoActivity.java   //总入口， P80
IjkVideoView.java
surfaceRenderView.java
	
-----------------ios平台接口文件----------------------
IJKMoviePlayerViewController.m
IJKFFMoviePlayerController.m

---------------一些结构体初始化的位置-------------------------
1. VideoState
stream_open()中创建并初始化：
	is = av_mallocz(sizeof(VideoState));
    if (!is)
        return NULL;
    is->filename = av_strdup(filename);
	
2. FFPlayer
ffp_create()中创建并初始化：
	FFPlayer* ffp = (FFPlayer*) av_mallocz(sizeof(FFPlayer));
    if (!ffp)
        return NULL;

    msg_queue_init(&ffp->msg_queue);
    ffp->af_mutex = SDL_CreateMutex();
			
--------------------主要参考文档------------------
http://www.jianshu.com/p/daf0a61cc1e0

-------------------精确seek-------------------
queue_picture()
audio_thread()

read_thread()
	完成seek操作的具体操作。

enable_accurate_seek = 1；
video_accurate_seek_req = 1；
audio_accurate_seek_req = 1；
is->step = 1;

--------------------音频数据流----------------------------
1. read_thread线程从媒体文件中取出demux后的数据，并将音频数据送到is->audioq队列中。
主要调用函数：
av_read_frame(ic, pkt)：从媒体文件中取出demux后的数据
packet_queue_put(&is->audioq, pkt, p_pkttime)；将音频数据送入音频队列。

2. audio_thread线程负责从队列中取出数据，送给解码器解码，然后送到sample队列中。
主要调用函数：
decoder_decode_frame(): 调用packet_queue_get_or_buffering()从audioq队列中取出数据，送给avcodec_decode_audio4()完成解码。
frame_queue_peek_writable: 负责将解码后的音频帧送入is->sampq队列中。
			注：在pause状态，由于aout_thread线程会被暂停，造成sampq队列会满，此时frame_queue_peek_writable()也会挂起audio_thread线程。

3. aout_thread线程，通过回调函数从audioq中取到音频帧，在android下，调用audiotrack实现音频的播放。

--------------------视频数据流----------------------------
1. read_thread线程从媒体文件中取出demux后的数据，并将视频数据送到is->videoq队列中。
主要调用函数：
av_read_frame(ic, pkt)：从媒体文件中取出demux后的数据
packet_queue_put(&is->videoq, pkt, p_pkttime)；将音频数据送入音频队列。

2. ffplay_video_thread线程负责从队列中取出数据，送给解码器解码，然后送到sample队列中。
主要调用函数：
get_video_frame(): 通过调用decoder_decode_frame()，调用packet_queue_get_or_buffering()从videoq队列中取出数据，送给avcodec_decode_video2()完成解码。
queue_picture(): 调用frame_queue_push(&is->pictq)将解码后的视频帧送入pictq队列中。
				注：queue_picture()中负责实现精准seek。

3. video_refresh_thread线程负责视频的渲染。

----------------ffplay thread------------------------
1 static int read_thread(void *arg)  //This thread gets the stream from the disk or the network
该线程主要负责：打开媒体文件，创建音频解码器线程，创建视频解码器线程，从媒体文件中不断的读出demux后的数据。

1) ret = stream_component_open(ffp, st_index[AVMEDIA_TYPE_AUDIO]);  ///* open a given stream. Return 0 if OK */
打开音频解码器。在此会打开相应解码器，并创建相应的解码线程。
		/* prepare audio output */
		if ((ret = audio_open(ffp, channel_layout, nb_channels, sample_rate, &is->audio_tgt)) < 0)
            goto fail;
        ffp_set_audio_codec_info(ffp, AVCODEC_MODULE_NAME, avcodec_get_name(avctx->codec_id));
		
		decoder_init(&is->auddec, avctx, &is->audioq, is->continue_read_thread);
        if ((is->ic->iformat->flags & (AVFMT_NOBINSEARCH | AVFMT_NOGENSEARCH | AVFMT_NO_BYTE_SEEK)) && !is->ic->iformat->read_seek) {
            is->auddec.start_pts = is->audio_st->start_time;
            is->auddec.start_pts_tb = is->audio_st->time_base;
        }
        if ((ret = decoder_start(&is->auddec, audio_thread, ffp, "ff_audio_dec")) < 0)
            goto fail;
        SDL_AoutPauseAudio(ffp->aout, 0);

2) ret = stream_component_open(ffp, st_index[AVMEDIA_TYPE_VIDEO]);  ///* open a given stream. Return 0 if OK */
打开视频解码器。在此会打开相应解码器，并创建相应的解码线程。
		decoder_init(&is->viddec, avctx, &is->videoq, is->continue_read_thread);
        ffp->node_vdec = ffpipeline_open_video_decoder(ffp->pipeline, ffp);  //实际调用func_open_video_decoder() in ffpipeline_android.c
        if (!ffp->node_vdec)
            goto fail;
        if ((ret = decoder_start(&is->viddec, video_thread, ffp, "ff_video_dec")) < 0)
            goto fail;
        is->queue_attachments_req = 1;

3) ret = av_read_frame(ic, pkt);
在无限循环中读取媒体数据，得到的是音视频分离的解码前数据。

将读出来的音频数据放入音频队列中。
packet_queue_put(&is->audioq, pkt, p_pkttime);

将读出来的视频数据放入视频队列中。
packet_queue_put(&is->videoq, pkt, p_pkttime);

2. static int audio_thread(void *arg)
从音频数据队列audioq中读出数据，通过decoder_decode_frame()解码，再通过frame_queue_push()送到音频帧队列中。
	audio_thread(void *arg)  //ff_ffplay.c
	decoder_decode_frame(FFPlayer *ffp, Decoder *d, AVFrame *frame, AVSubtitle *sub, AVPacketTime *p_pkttime) 
	frame_queue_push(&is->sampq);

3. static int aout_thread(void *arg)  //android平台上在文件ijksdl_aout_android_audiotrack.c
负责音频播放的线程，在创建音频解码线程的时候创建。
在pause状态，该线程会挂起，停止audiotrack，不再从is->sampq队列中读取数据。
1)创建过程：audio_open(ffp, channel_layout, nb_channels, sample_rate, &is->audio_tgt)  //prepare audio output
		SDL_AoutOpenAudio(ffp->aout, &wanted_spec, &spec) //wanted_spec中设置回调函数 sdl_audio_callback()
		aout->open_audio(aout, desired, obtained)  //实际指向aout_open_audio(SDL_Aout *aout, const SDL_AudioSpec *desired, SDL_AudioSpec *obtained)
		aout_open_audio_n(JNIEnv *env, SDL_Aout *aout, const SDL_AudioSpec *desired, SDL_AudioSpec *obtained)
			在android下，该函数会创建audiotrack播放音频，同时创建aout_thread，该线程负责从解码后的sample队列中拿到数据并播放。
2)主要操作：通过函数指针audio_cblk指向的回调函数sdl_audio_callback()，获得PCM数据，通过audiotrack实现在android平台上的播放。
3) sdl_audio_callback()函数的主要过程：
		sdl_audio_callback()   //ff_ffplay.c
		audio_decode_frame(FFPlayer *ffp)		//Decode one audio frame and return its uncompressed size.
		该函数负责从is->sampq队列中取出pcm数据，如果if (is->paused || is->step)， 怎直接返回-1。


4. static int video_thread(void *arg)
实际调用的是static int ffplay_video_thread(void *arg)  //ff_ffplay.c
	for (;;) {
        ret = get_video_frame(ffp, frame);
        ......
        ret = queue_picture(ffp, frame, pts, duration, av_frame_get_pkt_pos(frame), is->viddec.pkt_serial);
    }

	
5 static int video_refresh_thread(void *arg)
渲染线程为video_refresh_thread，最后渲染图像的方法为video_image_display2
	vp = frame_queue_peek_last(&is->pictq);
    ......

    SDL_VoutDisplayYUVOverlay(ffp->vout, vp->bmp);
	
-------------ffplay struct------------------
http://blog.csdn.net/xipiaoyouzi/article/details/74280170

1. int ffp_prepare_async_l(FFPlayer *ffp, const char *file_name)   //called by _prepareAsync 
1.1 ffp->aout = ffpipeline_open_audio_output(ffp->pipeline, ffp);

1.2 VideoState *is = stream_open(ffp, file_name, NULL);

1.2.1 创建存放video解码前数据的videoq,存放解码后数据的pictq
frame_queue_init(&is->pictq, &is->videoq, ffp->pictq_size, 1)

1.2.2 创建存放audio解码前数据的audioq,存放解码后数据的sampq
frame_queue_init(&is->sampq, &is->audioq, SAMPLE_QUEUE_SIZE, 1)

1.2.3 is->video_refresh_tid = SDL_CreateThreadEx(&is->_video_refresh_tid, video_refresh_thread, ffp, "ff_vout");
创建视频渲染线程 video_refresh_thread。

1.2.4 is->read_tid = SDL_CreateThreadEx(&is->_read_tid, read_thread, ffp, "ff_read");
创建读数据线程 read_thread

2. 

------------------API-----------------------
1. prepare 
{ "_prepareAsync",          "()V",      (void *) IjkMediaPlayer_prepareAsync },		//ijkplayer_jni.c
IjkMediaPlayer_prepareAsync(JNIEnv *env, jobject thiz)					//ijkplayer_jni.c
ijkmp_prepare_async(IjkMediaPlayer *mp)					//ijkplayer.c
ijkmp_prepare_async_l()							//ijkplayer.c
ffp_prepare_async_l()   						//ff_ffplay.c
stream_open()

2. seek
{ "seekTo",                 "(J)V",     (void *) IjkMediaPlayer_seekTo },      //ijkplayer_jni.c
jkMediaPlayer_seekTo(JNIEnv *env, jobject thiz, jlong msec)
ijkmp_seek_to(IjkMediaPlayer *mp, long msec)   				//ijkplayer.c
ffp_seek_to_l(FFPlayer *ffp, long msec)   				//ff_ffplay.c, 这里要区分精准seek还是普通seek
stream_seek(VideoState *is, int64_t pos, int64_t rel, int seek_by_bytes)

is->seek_req

3. pause
{ "_pause",                 "()V",      (void *) IjkMediaPlayer_pause },	//ijkplayer_jni.c
ijkmp_pause(IjkMediaPlayer *mp)		//ijkplayer.c
ffp_pause_l(FFPlayer *ffp)      	//ff_ffplay.c
toggle_pause(FFPlayer *ffp, int pause_on)
toggle_pause_l(FFPlayer *ffp, int pause_on)
stream_update_pause_l(FFPlayer *ffp)
stream_toggle_pause_l(FFPlayer *ffp, int pause_on)  

-------------------sample-------------
AndroidManifest.xml
class SampleMediaActivity   //SampleMediaActivity.java
class SampleMediaListFragment //SampleMediaListFragment.java, 在此处可以修改测试源
class VideoActivity  //VideoActivity.java
class IjkVideoView   //ijkVideoView.java
mMediaPlayer = createPlayer(mSettings.getPlayer());

------------------------ijmediaplayer在android下的创建过程---------------------------
{ "native_setup",           "(Ljava/lang/Object;)V",      (void *) IjkMediaPlayer_native_setup },
IjkMediaPlayer_native_setup()   //Ijkplayer_jni.c
ijkmp_android_create()    		//Ijkplayer_android.c 
ijkmp_create()					//Ijkplayer.c
ffp_create() 			        //Ff_ffplay.c, Ff_ffplay_def.h, FFPlayer* ffp

ios类似
http://blog.csdn.net/xipiaoyouzi/article/details/74280170
ijkmp_ios_create（）

--------------主要文件---------------------------------
KSYMediaPlayer.java
ijkplayer_jni.c
ijkplayer.c  //IjkMediaPlayer是一个封装的结构体, ijkmp_create()
ff_ffplay.c
